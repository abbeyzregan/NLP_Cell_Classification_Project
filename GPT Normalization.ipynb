{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7814ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change default huggingface cache directory\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/tmp/huggingface/hub\"\n",
    "\n",
    "# Import needed libraries \n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "from transformers import BioGptModel, BioGptConfig, BioGptForCausalLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import traceback\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import random\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, roc_auc_score, precision_recall_curve, classification_report\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler, StandardScaler, QuantileTransformer\n",
    "\n",
    "#Scanorama Batch Normalization \n",
    "import scanorama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17b46f9",
   "metadata": {},
   "source": [
    "## Step 1: Generate Question + Answers from GPT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35e957",
   "metadata": {},
   "source": [
    "trying BioMedLM model to see if I like it better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7303c655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_dichek shape:  (15431,)\n",
      "y_pedroza shape:  (9745,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data for Normalization \n",
    "# Reading the existing data into dataframes \n",
    "df_dichek = pd.read_csv('all_data_matrix_logNorm.csv', index_col=0,header=0).T\n",
    "df_pedroza = pd.read_csv('pedroza_data_matrix_logNorm.csv',index_col=0,header=0).T\n",
    "\n",
    "df_dichek_metadata = pd.read_csv('all_metadata.csv',index_col=0,header=0)\n",
    "df_pedroza_metadata = pd.read_csv('pedroza_metadata.csv',index_col=0,header=0)\n",
    "\n",
    "#Changing indices so that they match and the two data sets can be joined together \n",
    "df_dichek.index = df_dichek.index.str.replace('.','-')\n",
    "df_pedroza.index = df_pedroza.index.str.replace('.', '-')\n",
    "\n",
    "#make it so that df_dichek and df_pedroza have the same genes involved \n",
    "intersecting_genes = df_dichek.columns.intersection(df_pedroza.columns)\n",
    "X_dichek = df_dichek[intersecting_genes]\n",
    "X_pedroza = df_pedroza[intersecting_genes]\n",
    "\n",
    "# Split metadata into the SHF = 0, CNC = 1 \n",
    "y_dichek = (df_dichek_metadata['lineage']=='CNC').astype('int')\n",
    "y_pedroza  = (df_pedroza_metadata['lineage'] == 'CNC').astype('int')\n",
    "print(\"y_dichek shape: \",y_dichek.shape)\n",
    "print(\"y_pedroza shape: \", y_pedroza.shape)\n",
    "\n",
    "# Transform into np arrays \n",
    "np_dichek = X_dichek.to_numpy()\n",
    "np_pedroza = X_pedroza.to_numpy()\n",
    "datasets = [np_dichek, np_pedroza]\n",
    "\n",
    "#Make genes list \n",
    "num_genes = intersecting_genes.size\n",
    "genes_list = list()\n",
    "for i in range(0, num_genes): \n",
    "    genes_list.append(intersecting_genes[i])\n",
    "    \n",
    "nested_list = list()\n",
    "nested_list.append(genes_list.copy())\n",
    "nested_list.append(genes_list.copy())\n",
    "\n",
    "#Generate Corrected data\n",
    "# integrated, corrected, genes = scanorama.correct(datasets, nested_list, return_dimred=True)\n",
    "\n",
    "# #store batch corrected data in variables \n",
    "# df_batch_corrected_dichek = pd.DataFrame.sparse.from_spmatrix(corrected[0])\n",
    "# df_batch_corrected_pedroza = pd.DataFrame.sparse.from_spmatrix(corrected[1])\n",
    "# print(df_batch_corrected_dichek.shape)\n",
    "# print(df_batch_corrected_pedroza.shape)\n",
    "# integrated_dichek = integrated[0]\n",
    "# integrated_pedroza = integrated[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b668b52",
   "metadata": {},
   "source": [
    "## Step 2: Find the data with the highest standard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9569d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25176, 16855)\n",
      "(25176,)\n"
     ]
    }
   ],
   "source": [
    "X = pd.concat([X_dichek,X_pedroza]).to_numpy()\n",
    "y = pd.concat([y_dichek, y_pedroza]).to_numpy()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be2e4c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4609 10530  3785 ...   983 14921 11736]\n",
      "(16855,)\n",
      "0.0\n",
      "1.4157742311629988\n"
     ]
    }
   ],
   "source": [
    "standard_devs = np.zeros(X.shape[1])\n",
    "for i in range (0, X.shape[1]):\n",
    "    standard_devs[i] = np.std(X.T[i])\n",
    "indices = standard_devs.argsort() #indices sorted in reverse order \n",
    "print(indices)\n",
    "print(indices.shape)\n",
    "print(standard_devs[indices[0]])\n",
    "print(standard_devs[indices[X.shape[1] - 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f5adfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(25176, 1000)\n"
     ]
    }
   ],
   "source": [
    "top_1000_indices = indices[X.shape[1] - 1000:]\n",
    "top_1000_indices.sort()\n",
    "print(top_1000_indices.shape)\n",
    "X_top_1000 = pd.concat([X_dichek, X_pedroza]).iloc[:, top_1000_indices]\n",
    "print(X_top_1000.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e505e8",
   "metadata": {},
   "source": [
    "## Step 3: Create the array of strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"stanford-crfm/BioMedLM\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a297bfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m top_1000_genes \u001b[38;5;241m=\u001b[39m \u001b[43mX_top_1000\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(top_1000_genes)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "top_1000_genes = X_top_1000.columns\n",
    "print(top_1000_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede0ab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_descriptions = list()\n",
    "for i in range(200,300): \n",
    "    Query = f\"\"\"\n",
    "    Question <1>: How is TGFb related to the development of aortic aneurysms in the ascending aorta of mice? \n",
    "    Answer <2>: TGFb plays both a protective and pathogenic role in the development of aortic aneurysms, as some studies cite that TGFb signaling is protective against thoracic and abdominal disease in mouse models while other studies note that increased activity can be lethal in utero\n",
    "    Question <2>: How is {top_1000_genes[i]} related to the development of aortic aneurysms in the ascending aorta of mice? \n",
    "    Answer <2>: \n",
    "    \"\"\"\n",
    "    Query1 = f\"\"\"\n",
    "    Question <1>: How is {top_1000_genes[i]} related to CNC and SHF cells in the aortas of mice? \n",
    "    Answer <1>: \n",
    "    \"\"\"\n",
    "    input_text = Query.strip()\n",
    "    inputs = tokenizer(input_text, return_tensors='pt').to(device)\n",
    "#     print({k: v.shape for k, v in inputs.items()})\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=200,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7,\n",
    "        bad_words_ids= tokenizer([\"\\\\\", ' [', \"[\", ']', \"@\", '=', '#', '^', '*', ' *', ' #', '{', ' {', '}', ' ([', '~', ' ~', '\\n', ' <', '<', '>']).input_ids,\n",
    "    )\n",
    "\n",
    "    answer_ids = output_ids[0][len(inputs.input_ids[0]):]\n",
    "    answer_text = tokenizer.decode(answer_ids)\n",
    "    answer_text = answer_text.strip()\n",
    "#     print(input_text)\n",
    "#     print(answer_text)\n",
    "    text_descriptions.append(answer_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea257c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(text_descriptions))\n",
    "print(text_descriptions[0])\n",
    "print(text_descriptions[99])\n",
    "pd.DataFrame(text_descriptions, columns=['text_descriptions']).to_csv(\"data/top_1000_genes_cells200-300_Query1_answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d31847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                                           0\n",
      "text_descriptions    Nexn is a component of the extracellular matri...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "file_names = [\"data/top_1000_genes_cells100-200_Query1_answers.csv\", \"data/top_1000_genes_cells200-300_Query1_answers.csv\", \"data/top_1000_genes_cells300-400_Query1_answers.csv\", \"data/top_1000_genes_cells400-500_Query1_answers.csv\", \"data/top_1000_genes_cells500-600_Query1_answers.csv\", \"data/top_1000_genes_cells600-700_Query1_answers.csv\", \"data/top_1000_genes_cells300-400_Query1_answers.csv\", \"data/top_1000_genes_cells700-800_Query1_answers.csv\", \"data/top_1000_genes_cells800-900_Query1_answers.csv\", \"data/top_1000_genes_cells900-1000_Query1_answers.csv\"]\n",
    "gene_descriptions_Query1 = pd.read_csv(\"data/top_1000_genes_cells0-100_Query1_answers.csv\")\n",
    "for i in range(0, len(file_names)):\n",
    "    new_descripts = pd.read_csv(file_names[i])\n",
    "    gene_descriptions_Query1 = pd.concat([gene_descriptions_Query1, new_descripts])\n",
    "print(gene_descriptions_Query1.iloc[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aee47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Embeddings \n",
    "model = SentenceTransformer('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb')\n",
    "embeddings = list()\n",
    "for i in range(0,1000): \n",
    "    embeddings.append(model.encode(gene_descriptions_Query1.iloc[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06054707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.64041317 0.65253288 ... 0.67523646 0.69934809 0.71627951]\n",
      " [0.64041317 1.         0.66670632 ... 0.56841803 0.58007854 0.57984048]\n",
      " [0.65253288 0.66670632 0.99999982 ... 0.6492011  0.60106933 0.57205641]\n",
      " ...\n",
      " [0.67523646 0.56841803 0.6492011  ... 1.00000012 0.54780734 0.54762679]\n",
      " [0.69934809 0.58007854 0.60106933 ... 0.54780734 1.00000012 0.66877347]\n",
      " [0.71627951 0.57984048 0.57205641 ... 0.54762679 0.66877347 0.99999994]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros([1000,1000])\n",
    "for i in range(0,1000):\n",
    "    for j in range(0,1000):\n",
    "        similarity = util.pytorch_cos_sim(embeddings[i], embeddings[j])\n",
    "        similarity_matrix[i][j] = similarity[0][0]\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba0c42fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save similarity matrix as a dataframe object \n",
    "df_similarity_matrix = pd.DataFrame(similarity_matrix, columns = X_top_1000.columns)\n",
    "df_similarity_matrix.to_csv('Query1_similarity_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5775a3",
   "metadata": {},
   "source": [
    "## Step 4: Normalize data using similarity matrix \n",
    "Now, we use the generated similarity matrix to normalize the baseline data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "045d867f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n",
      "[[1.         0.64041317 0.65253288 ... 0.67523646 0.69934809 0.71627951]\n",
      " [0.64041317 1.         0.66670632 ... 0.56841803 0.58007854 0.57984048]\n",
      " [0.65253288 0.66670632 0.99999982 ... 0.6492011  0.60106933 0.57205641]\n",
      " ...\n",
      " [0.67523646 0.56841803 0.6492011  ... 1.00000012 0.54780734 0.54762679]\n",
      " [0.69934809 0.58007854 0.60106933 ... 0.54780734 1.00000012 0.66877347]\n",
      " [0.71627951 0.57984048 0.57205641 ... 0.54762679 0.66877347 0.99999994]]\n"
     ]
    }
   ],
   "source": [
    "# Read similarity matrix \n",
    "similarity_matrix = pd.read_csv('Query1_similarity_matrix.csv').to_numpy()\n",
    "similarity_matrix = np.delete(similarity_matrix, 0, 1)\n",
    "print(similarity_matrix.shape)\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b6bb9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Create a random matrix \n",
    "type1 = 'random matrix'\n",
    "random_matrix = np.random.rand(1000,1000)\n",
    "print(random_matrix.shape)\n",
    "\n",
    "type2 = 'original similarity matrix'\n",
    "\n",
    "# Try different types of normalization for the similarity matrix \n",
    "type3= 'MaxAbsScaler'\n",
    "transformer = MaxAbsScaler().fit(similarity_matrix)\n",
    "transformer\n",
    "sim_matrix_MaxAbsScaler = transformer.transform(similarity_matrix)\n",
    "print(sim_matrix_MaxAbsScaler.shape)\n",
    "\n",
    "type4 = 'MinMaxScaler'\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(similarity_matrix)\n",
    "sim_matrix_MinMaxScaler = scaler.transform(similarity_matrix)\n",
    "print(sim_matrix_MinMaxScaler.shape)\n",
    "\n",
    "type5 = 'StandardScaler'\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(similarity_matrix)\n",
    "sim_matrix_StandardScaler = scaler.transform(similarity_matrix)\n",
    "print(sim_matrix_StandardScaler.shape)\n",
    "\n",
    "type6 = 'QuantileTransformer'\n",
    "qt = QuantileTransformer(n_quantiles=10, random_state=0)\n",
    "sim_matrix_QuantileTransformer = qt.fit_transform(similarity_matrix)\n",
    "print(sim_matrix_QuantileTransformer.shape)\n",
    "\n",
    "similarityMatrices = [random_matrix, similarity_matrix, sim_matrix_MaxAbsScaler, sim_matrix_MinMaxScaler, sim_matrix_StandardScaler, sim_matrix_QuantileTransformer]\n",
    "normalizationTypes = [type1, type2, type3, type4, type5, type6, 'baseline data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95c8196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "QuantileTransformer\n"
     ]
    }
   ],
   "source": [
    "list_X_normalized = list()\n",
    "for i in range(0, len(similarityMatrices)):\n",
    "    list_X_normalized.append(np.matmul(X_top_1000.to_numpy(), similarityMatrices[i]))\n",
    "list_X_normalized.append(X_top_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd228bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5559968228752978\n",
      "Precision: 0.5742441209406495\n",
      "Recall: 0.884442911348741\n",
      "ROC AUC : 0.5017374845504469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.11      0.17      2137\n",
      "           1       0.57      0.88      0.70      2899\n",
      "\n",
      "    accuracy                           0.56      5036\n",
      "   macro avg       0.49      0.50      0.44      5036\n",
      "weighted avg       0.51      0.56      0.47      5036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(X_top_1000.shape[0], X_top_1000.shape[1])\n",
    "y = pd.concat([y_dichek, y_pedroza])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "rf = RandomForestClassifier() \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "y_prob = rf.predict_proba(X_test)\n",
    "\n",
    "y_prob_new = np.empty((y_prob.shape[0], ))\n",
    "for j in range(0, y_prob.shape[0]):\n",
    "    y_prob_new[j] = y_prob[j][1]\n",
    "\n",
    "# Accuracy Classification Score \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_prob_new)\n",
    "classification = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"ROC AUC :\", auc_score)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c2092eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try comparing the for the spearman correlation \n",
    "gene_similarity_matrix = np.zeros((1000,1000))\n",
    "X_T = X_top_1000.to_numpy().T\n",
    "for i in range(0,1000):\n",
    "    for j in range(0,1000): \n",
    "        gene_similarity_matrix[i][j] = util.pytorch_cos_sim(X_T[i], X_T[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6c55372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029315228842511462\n"
     ]
    }
   ],
   "source": [
    "gene_sim_T = gene_similarity_matrix.T\n",
    "sim_T = similarity_matrix.T\n",
    "spearman_vals = list()\n",
    "vals = np.zeros(1000)\n",
    "for i in range(0,1000):\n",
    "    spearman_vals.append(scipy.stats.spearmanr(gene_sim_T[i], sim_T[i]))\n",
    "    vals[i] = scipy.stats.spearmanr(gene_sim_T[i], sim_T[i])[0]\n",
    "print(np.mean(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47877ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random matrix\n",
      "Accuracy: 0.7720413026211279\n",
      "Precision: 0.7552941176470588\n",
      "Recall: 0.8904299583911235\n",
      "ROC AUC : 0.8555929973859108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.61      0.70      2152\n",
      "           1       0.76      0.89      0.82      2884\n",
      "\n",
      "    accuracy                           0.77      5036\n",
      "   macro avg       0.78      0.75      0.76      5036\n",
      "weighted avg       0.78      0.77      0.77      5036\n",
      "\n",
      "original similarity matrix\n",
      "Accuracy: 0.6767275615567911\n",
      "Precision: 0.6899390243902439\n",
      "Recall: 0.7874043145441892\n",
      "ROC AUC : 0.7282747101996464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.58      2162\n",
      "           1       0.69      0.79      0.74      2874\n",
      "\n",
      "    accuracy                           0.68      5036\n",
      "   macro avg       0.67      0.66      0.66      5036\n",
      "weighted avg       0.67      0.68      0.67      5036\n",
      "\n",
      "MaxAbsScaler\n",
      "Accuracy: 0.6685861795075456\n",
      "Precision: 0.6787234042553192\n",
      "Recall: 0.7848857644991213\n",
      "ROC AUC : 0.7142298057479111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58      2191\n",
      "           1       0.68      0.78      0.73      2845\n",
      "\n",
      "    accuracy                           0.67      5036\n",
      "   macro avg       0.66      0.65      0.65      5036\n",
      "weighted avg       0.67      0.67      0.66      5036\n",
      "\n",
      "MinMaxScaler\n",
      "Accuracy: 0.6767275615567911\n",
      "Precision: 0.6947496947496947\n",
      "Recall: 0.7837465564738292\n",
      "ROC AUC : 0.7236059049044083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.53      0.58      2132\n",
      "           1       0.69      0.78      0.74      2904\n",
      "\n",
      "    accuracy                           0.68      5036\n",
      "   macro avg       0.67      0.66      0.66      5036\n",
      "weighted avg       0.67      0.68      0.67      5036\n",
      "\n",
      "StandardScaler\n",
      "Accuracy: 0.710087370929309\n",
      "Precision: 0.7198038013488657\n",
      "Recall: 0.8113337940566689\n",
      "ROC AUC : 0.7710370372521272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.57      0.63      2142\n",
      "           1       0.72      0.81      0.76      2894\n",
      "\n",
      "    accuracy                           0.71      5036\n",
      "   macro avg       0.71      0.69      0.70      5036\n",
      "weighted avg       0.71      0.71      0.71      5036\n",
      "\n",
      "QuantileTransformer\n",
      "Accuracy: 0.7003574265289912\n",
      "Precision: 0.7046959662853702\n",
      "Recall: 0.8159637504356919\n",
      "ROC AUC : 0.7547799842467329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61      2167\n",
      "           1       0.70      0.82      0.76      2869\n",
      "\n",
      "    accuracy                           0.70      5036\n",
      "   macro avg       0.70      0.68      0.68      5036\n",
      "weighted avg       0.70      0.70      0.69      5036\n",
      "\n",
      "baseline data\n",
      "Accuracy: 0.9314932486100079\n",
      "Precision: 0.9208152355496158\n",
      "Recall: 0.9622905027932961\n",
      "ROC AUC : 0.9820008751556119\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      2172\n",
      "           1       0.92      0.96      0.94      2864\n",
      "\n",
      "    accuracy                           0.93      5036\n",
      "   macro avg       0.93      0.93      0.93      5036\n",
      "weighted avg       0.93      0.93      0.93      5036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train using the normalized data \n",
    "for i in range(0, len(list_X_normalized)):\n",
    "    X = list_X_normalized[i]\n",
    "    y = pd.concat([y_dichek, y_pedroza])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    rf = RandomForestClassifier() \n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_prob = rf.predict_proba(X_test)\n",
    "\n",
    "    y_prob_new = np.empty((y_prob.shape[0], ))\n",
    "    for j in range(0, y_prob.shape[0]):\n",
    "        y_prob_new[j] = y_prob[j][1]\n",
    "\n",
    "    # Accuracy Classification Score \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_prob_new)\n",
    "    classification = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(normalizationTypes[i])\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"ROC AUC :\", auc_score)\n",
    "    print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4bde7469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random matrix\n",
      "Accuracy: 0.8515539668354681\n",
      "Precision: 0.8418247374196582\n",
      "Recall: 0.9170081967213115\n",
      "ROC AUC : 0.9310594035418652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81      4215\n",
      "           1       0.84      0.92      0.88      5856\n",
      "\n",
      "    accuracy                           0.85     10071\n",
      "   macro avg       0.86      0.84      0.84     10071\n",
      "weighted avg       0.85      0.85      0.85     10071\n",
      "\n",
      "original similarity matrix\n",
      "Accuracy: 0.7945586337007249\n",
      "Precision: 0.7863831137914616\n",
      "Recall: 0.8726664318421979\n",
      "ROC AUC : 0.8728552789842178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.75      4393\n",
      "           1       0.79      0.87      0.83      5678\n",
      "\n",
      "    accuracy                           0.79     10071\n",
      "   macro avg       0.80      0.78      0.79     10071\n",
      "weighted avg       0.80      0.79      0.79     10071\n",
      "\n",
      "MaxAbsScaler\n",
      "Accuracy: 0.8024029391321617\n",
      "Precision: 0.806574559313959\n",
      "Recall: 0.8680567424371902\n",
      "ROC AUC : 0.8752706832631194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75      4220\n",
      "           1       0.81      0.87      0.84      5851\n",
      "\n",
      "    accuracy                           0.80     10071\n",
      "   macro avg       0.80      0.79      0.79     10071\n",
      "weighted avg       0.80      0.80      0.80     10071\n",
      "\n",
      "MinMaxScaler\n",
      "Accuracy: 0.8129282097110515\n",
      "Precision: 0.8109532173079994\n",
      "Recall: 0.8788717771240699\n",
      "ROC AUC : 0.8838041317448029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      4292\n",
      "           1       0.81      0.88      0.84      5779\n",
      "\n",
      "    accuracy                           0.81     10071\n",
      "   macro avg       0.81      0.80      0.81     10071\n",
      "weighted avg       0.81      0.81      0.81     10071\n",
      "\n",
      "StandardScaler\n",
      "Accuracy: 0.8141197497765862\n",
      "Precision: 0.8082623777988016\n",
      "Recall: 0.8865444482877897\n",
      "ROC AUC : 0.8895972329204591\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      4289\n",
      "           1       0.81      0.89      0.85      5782\n",
      "\n",
      "    accuracy                           0.81     10071\n",
      "   macro avg       0.82      0.80      0.81     10071\n",
      "weighted avg       0.81      0.81      0.81     10071\n",
      "\n",
      "QuantileTransformer\n",
      "Accuracy: 0.8136232747492801\n",
      "Precision: 0.8046284634760705\n",
      "Recall: 0.8893335653384374\n",
      "ROC AUC : 0.8925397991503269\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77      4324\n",
      "           1       0.80      0.89      0.84      5747\n",
      "\n",
      "    accuracy                           0.81     10071\n",
      "   macro avg       0.82      0.80      0.81     10071\n",
      "weighted avg       0.82      0.81      0.81     10071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train using baseline dataset and the normalized dataset together \n",
    "y = pd.concat([y_dichek,y_pedroza, y_dichek, y_pedroza]).to_numpy()\n",
    "for i in range(0, len(list_X_normalized) -1):\n",
    "    X = np.append(X_top_1000, list_X_normalized[i], axis = 0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    rf = RandomForestClassifier() \n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_prob = rf.predict_proba(X_test)\n",
    "\n",
    "    y_prob_new = np.empty((y_prob.shape[0], ))\n",
    "    for j in range(0, y_prob.shape[0]):\n",
    "        y_prob_new[j] = y_prob[j][1]\n",
    "\n",
    "    # Accuracy Classification Score \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_prob_new)\n",
    "    classification = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(normalizationTypes[i])\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"ROC AUC :\", auc_score)\n",
    "    print(classification)\n",
    "\n",
    "#Try using concatenation of both, use original and augmented data matrix \n",
    "# For augmeneted dataset, try to do a smaller training set, 30 train 70 test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2ceb94",
   "metadata": {},
   "source": [
    "## Step 6: Try using sentiment Analysis for Filtering\n",
    "First, I will use the results from sentiment analysis to filter the data and choose only the genes with a positive sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0c35a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "# Perform Sentiment Analysis on the results that were generated here \n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "data = list()\n",
    "for i in range(0, 1000):\n",
    "    data.append(gene_descriptions_Query1.iloc[i][1])\n",
    "sentiments = sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b04b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 31, 53, 67, 69, 85, 86, 104, 134, 149, 185, 186, 189, 190, 196, 202, 203, 246, 252, 254, 259, 265, 269, 277, 292, 297, 303, 304, 320, 323, 340, 355, 361, 384, 393, 402, 407, 414, 415, 417, 431, 458, 460, 461, 463, 477, 483, 488, 489, 495, 496, 502, 511, 523, 538, 541, 554, 558, 567, 577, 615, 627, 631, 644, 649, 654, 663, 668, 694, 696, 703, 704, 720, 723, 740, 755, 761, 784, 793, 809, 820, 829, 835, 853, 863, 896, 909, 919, 929, 931, 935, 944, 949, 963, 964, 977, 982, 985, 988, 989, 996]\n",
      "positiveSentis_indices length:  101\n",
      "Positive Sentiment Sentence: Hspd1 may play a role in the development of aortic aneurysms through its ability to interact with the TGFb pathway. Hspd1 may also be regulated by TGFb, which in turn may be regulated by Hspd1. Hspd1 may be a biomarker for TGFb activity in the aorta. Hspd1 may also be a therapeutic target for treatment of aortic aneurysms, as Hspd1 is a chaperone, which in turn can affect TGFb activity and potentially prevent or delay aneurysm formation.\n",
      "Positive Sentiment Sentence: Actr3 is a component of the TGFb/Activin pathway and is a strong candidate for further study as a modifier of the development of aneurysms in the ascending aorta. A complete loss of function is lethal in utero, while a partial loss of function does not seem to lead to a high incidence of aneurysm formation. However, further studies in mice with heterozygous deletion of Actr3, with or without other modifiers, may prove insightful. It is possible that the effects of a heterozygous mutation are not as severe as a homozygous mutation in the human population. The use of a mouse model would allow for a more detailed study of the role of Actr3 in the development of aortic aneurysms in the ascending aorta. The use of Actr3 knockout mice may also prove insightful in the study of other TGFb/Activin signaling pathway genes that have been associated with aortic aneurysms in humans. A complete loss of function would be lethal in utero, while a partial loss of function would not\n",
      "Positive Sentiment Sentence: Fmo2 is a protective factor against the development of ascending aortic aneurysms in mice. It is highly expressed in the aortic wall of mice with aneurysms and appears to protect against the development of aneurysms. Fmo2 is an enzyme that converts L‐arginine to L‐citrulline and nitric oxide (NO). It also appears to have a protective role against the development of aortic aneurysms in mice. Fmo2 is highly expressed in the aortic wall of mice with aneurysms and appears to protect against the development of aneurysms. Fmo2 is an enzyme that converts L‐arginine to L‐citrulline and nitric oxide (NO). It also appears to have a protective role against the development of aortic aneurysms in mice. Fmo2 is highly expressed in the aortic wall of mice with aneurysms and appears to protect against the development of aneurysms. Fmo2 is an enzyme that converts L‐arginine to L‐citrulline and nitric oxide (NO). It also appears to\n",
      "Negative Sentiment Sentence: Hspe1 is not related to the development of aortic aneurysms in the ascending aorta of mice.  These mice do not have mutations in the gene coding for Hspe1, but do have increased activity of this enzyme.  However, in the thoracic and abdominal aorta of these mice, Hspe1 may be related to the development of aortic aneurysms.  However, this is not the case in the ascending aorta.  These mice do not have mutations in the gene coding for Hspe1, but do have increased activity of this enzyme.  However, in the thoracic and abdominal aorta of these mice, Hspe1 may be related to the development of aortic aneurysms.  However, this is not the case in the ascending aorta.  These mice do not have mutations in the gene coding for Hspe1, but do have increased activity of this enzyme.  However, in the thoracic and abdominal aorta of these mice, Hspe1\n",
      "Negative Sentiment Sentence: Ubxn4 is a ubiquitin ligase that is highly expressed in the heart and is known to regulate protein turnover by targeting proteins for degradation. Recent studies have shown that Ubxn4 is an important regulator of TGFb signaling, and mutations in Ubxn4 are known to cause the disease Marfan syndrome. While Ubxn4 has been shown to be protective against aneurysm development in the ascending aorta of mice, studies have not yet examined the role of Ubxn4 in the descending thoracic aorta or the role of Ubxn4 in the development of aortic aneurysms in the abdominal aorta of mice.\n",
      "Negative Sentiment Sentence: Fmo3 has not been directly linked to the development of aortic aneurysms. However, Fmo3 is a key enzyme in the metabolism of AAAs and it has been found to be increased in the adventitia of aneurysms in humans. Fmo3 is also known to be increased in the liver of mice with aortic aneurysms and has been associated with increased inflammation, and oxidative stress. Fmo3 is also known to be increased in the aortic wall in mice with aortic aneurysms and can be modulated by the microbiome. There is no direct evidence to show that Fmo3 plays a role in the development of aortic aneurysms in mice. However, Fmo3 is known to be a key enzyme in the metabolism of AAAs and it has been found to be increased in the adventitia of aneurysms in humans. Fmo3 is also known to be increased in the liver of mice with aortic aneurysms and has been associated with increased inflammation, and oxidative stress. There is no direct evidence to show that Fmo3\n"
     ]
    }
   ],
   "source": [
    "positiveSentis_indices = list()\n",
    "for i in range(0,1000):\n",
    "    if(sentiments[i]['label'] == 'POSITIVE'):\n",
    "        positiveSentis_indices.append(i)\n",
    "print(positiveSentis_indices)\n",
    "print(\"positiveSentis_indices length: \" , len(positiveSentis_indices))\n",
    "for i in range(3):\n",
    "    print(\"Positive Sentiment Sentence:\", gene_descriptions_Query1.iloc[positiveSentis_indices[i]][1])\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"Negative Sentiment Sentence:\", gene_descriptions_Query1.iloc[positiveSentis_indices[i] + 1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d07002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25176, 101)\n"
     ]
    }
   ],
   "source": [
    "#Subset data based on genes indicated by sentiment analysis \n",
    "X_sentiment = X_top_1000.to_numpy().T[positiveSentis_indices].T\n",
    "print(X_sentiment.shape)\n",
    "\n",
    "list_sentiment_auc = np.zeros((4, 10 ))\n",
    "\n",
    "for i in range (10):\n",
    "    X = X_sentiment\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    rf = RandomForestClassifier() \n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_prob = rf.predict_proba(X_test)\n",
    "\n",
    "    y_prob_new = np.empty((y_prob.shape[0], ))\n",
    "    for j in range(0, y_prob.shape[0]):\n",
    "        y_prob_new[j] = y_prob[j][1]\n",
    "\n",
    "    # Accuracy Classification Score \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_prob_new)\n",
    "    classification = classification_report(y_test, y_pred)\n",
    "\n",
    "#     print(\"Sentiment Analysis\")\n",
    "#     print(\"Accuracy:\", accuracy)\n",
    "#     print(\"Precision:\", precision)\n",
    "#     print(\"Recall:\", recall)\n",
    "#     print(\"ROC AUC :\", auc_score)\n",
    "#     print(classification)\n",
    "    list_sentiment_auc[0][i] = accuracy\n",
    "    list_sentiment_auc[1][i] = precision\n",
    "    list_sentiment_auc[2][i] = recall\n",
    "    list_sentiment_auc[3][i] = auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7987b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 12, 13, 32, 47, 49, 70, 73, 86, 89, 93, 100, 101, 103, 106, 113, 131, 137, 139, 140, 158, 166, 170, 172, 173, 177, 178, 182, 185, 202, 208, 212, 225, 226, 232, 250, 255, 267, 282, 307, 315, 321, 345, 352, 356, 383, 391, 408, 432, 435, 437, 440, 445, 453, 459, 461, 466, 472, 473, 477, 499, 516, 518, 541, 563, 572, 579, 581, 586, 587, 592, 605, 612, 639, 669, 671, 688, 710, 712, 714, 730, 737, 762, 776, 779, 797, 801, 808, 824, 855, 862, 873, 911, 918, 923, 946, 965, 986, 991, 992, 993]\n",
      "(25176, 101)\n",
      "(25176, 101)\n",
      "(25176, 101)\n",
      "(25176, 101)\n",
      "(25176, 101)\n",
      "(25176, 101)\n",
      "(25176, 101)\n",
      "(25176, 101)\n",
      "(25176, 101)\n",
      "(25176, 101)\n"
     ]
    }
   ],
   "source": [
    "# Compare against randomly selecting 100 genes and using that for training \n",
    "rand_indices = random.sample(range(0,1000), 101)\n",
    "rand_indices.sort()\n",
    "print(rand_indices)\n",
    "\n",
    "list_random_auc = np.zeros((4, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    X_rand_100 = X_top_1000.to_numpy().T[rand_indices].T\n",
    "    print(X_rand_100.shape)\n",
    "\n",
    "    X = X_rand_100\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    rf = RandomForestClassifier() \n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_prob = rf.predict_proba(X_test)\n",
    "\n",
    "    y_prob_new = np.empty((y_prob.shape[0], ))\n",
    "    for j in range(0, y_prob.shape[0]):\n",
    "        y_prob_new[j] = y_prob[j][1]\n",
    "\n",
    "    # Accuracy Classification Score \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_prob_new)\n",
    "    classification = classification_report(y_test, y_pred)\n",
    "\n",
    "#     print(\"Sentiment Analysis\")\n",
    "#     print(\"Accuracy:\", accuracy)\n",
    "#     print(\"Precision:\", precision)\n",
    "#     print(\"Recall:\", recall)\n",
    "#     print(\"ROC AUC :\", auc_score)\n",
    "#     print(classification)\n",
    "    \n",
    "    list_random_auc[0][i] = accuracy\n",
    "    list_random_auc[1][i] = precision\n",
    "    list_random_auc[2][i] = recall\n",
    "    list_random_auc[3][i] = auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a57fcfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "TtestResult(statistic=-43.24711821697303, pvalue=9.434679543257187e-12, df=9)\n",
      "precision\n",
      "TtestResult(statistic=-34.7263393654471, pvalue=6.725565192245215e-11, df=9)\n",
      "recall\n",
      "TtestResult(statistic=-16.743416052360168, pvalue=4.3263428211678377e-08, df=9)\n",
      "roc auc\n",
      "TtestResult(statistic=-40.32777067214882, pvalue=1.764524557329655e-11, df=9)\n",
      "['accuracy', 'precision', 'recall', 'roc auc']\n",
      "random\n",
      "[[0.7680699  0.76409849 0.76687847 0.76310564 0.77084988 0.77065131\n",
      "  0.76211279 0.76528991 0.77680699 0.77442415]\n",
      " [0.76466936 0.74893358 0.75702934 0.76080957 0.76186131 0.76346389\n",
      "  0.75901038 0.75873595 0.76504914 0.77084601]\n",
      " [0.85729203 0.87101347 0.86729692 0.85729095 0.87100139 0.8672228\n",
      "  0.85867312 0.86551127 0.87403509 0.86865569]\n",
      " [0.83418186 0.84084089 0.83758248 0.83948849 0.84855469 0.84442045\n",
      "  0.83408161 0.83704593 0.84823045 0.8405332 ]]\n",
      "sentiment\n",
      "[[0.87112788 0.87609214 0.875695   0.8723193  0.86119936 0.8683479\n",
      "  0.87807784 0.87609214 0.87728356 0.87728356]\n",
      " [0.86328125 0.87340112 0.87541974 0.87343027 0.85407725 0.86386386\n",
      "  0.8725652  0.8675844  0.88190789 0.87757133]\n",
      " [0.92051371 0.91795932 0.91090147 0.91043748 0.90963432 0.91033755\n",
      "  0.92058516 0.92326474 0.91190476 0.91395992]\n",
      " [0.94000818 0.9440453  0.94151443 0.93721983 0.93245256 0.9365381\n",
      "  0.93984127 0.94531209 0.94068326 0.94293604]]\n"
     ]
    }
   ],
   "source": [
    "# calculating significance using a paired t-test \n",
    "types = [\"accuracy\", \"precision\", \"recall\", \"roc auc\"]\n",
    "\n",
    "for i in range (4): \n",
    "    print(types[i])\n",
    "    print(scipy.stats.ttest_rel(list_random_auc[i], list_sentiment_auc[i]))\n",
    "    \n",
    "print(types)\n",
    "print('random')\n",
    "print(list_random_auc)\n",
    "print('sentiment')\n",
    "print(list_sentiment_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35ae06",
   "metadata": {},
   "source": [
    "The analysis here seems to yield fairly good results, with random selection underperforming with respect to selecting the top 101 randomly. \n",
    "\n",
    "## Step 6: Normalize using the results from the sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5011cc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0007914304733276367, 0.0016494691371917725, 0.06643381714820862, 0.19121968746185303, 0.00024753808975219727]\n"
     ]
    }
   ],
   "source": [
    "# Normalize scores so they are either in the 0,1 range \n",
    "sentiment_scores = list()\n",
    "for i in range(0, len(sentiments)):\n",
    "    val = sentiments[i]['score']\n",
    "    if (sentiments[i]['label'] == 'NEGATIVE'):\n",
    "        val = val * -1\n",
    "    sentiment_scores.append((val /2) + 0.5)\n",
    "print(sentiment_scores[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9e20770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data using these sentiment scores \n",
    "X_normalized_sentiment = X_top_1000.to_numpy()\n",
    "for i in range(0, len(sentiment_scores)):\n",
    "    X_normalized_sentiment[:, i] *= sentiment_scores[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eace1cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis\n",
      "Accuracy: 0.8562351072279587\n",
      "Precision: 0.8317757009345794\n",
      "Recall: 0.9355290819901892\n",
      "ROC AUC : 0.9354740030715731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82      2182\n",
      "           1       0.83      0.94      0.88      2854\n",
      "\n",
      "    accuracy                           0.86      5036\n",
      "   macro avg       0.87      0.84      0.85      5036\n",
      "weighted avg       0.86      0.86      0.85      5036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X_normalized_sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "rf = RandomForestClassifier() \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "y_prob = rf.predict_proba(X_test)\n",
    "\n",
    "y_prob_new = np.empty((y_prob.shape[0], ))\n",
    "for j in range(0, y_prob.shape[0]):\n",
    "    y_prob_new[j] = y_prob[j][1]\n",
    "\n",
    "# Accuracy Classification Score \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_prob_new)\n",
    "classification = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Sentiment Analysis\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"ROC AUC :\", auc_score)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a828fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
